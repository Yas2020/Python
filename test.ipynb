{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys._is_gil_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of Python3.13, Global Interface Lock (GIL) can be diabled. That means Python interpreter becomes thread-free; There can be any number of threads per Python runtime. Since threads are more light weight than processes they bring more speed compared to processes. Removing GIL allows parallel programming using threads. But one should be careful when threads need to share states.  \n",
    "\n",
    "A Queue gives us the ability to perform lots of interprocess communication using native\n",
    "Python objects. This can be useful if you’re passing around objects with lots of state.\n",
    "Since the Queue lacks persistence, though, you probably don’t want to use them for jobs\n",
    "that might require robustness in the face of failure (e.g., if you lose power or a hard drive\n",
    "gets corrupted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Primes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find all prime numbers within a given range. This is a CPU-bound problem so we can think about parallel computing to speed up this task. We will try to implement this using different tools to see the gains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single thread in a process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "    from_i = 3\n",
    "    to_i = math.sqrt(n) + 1\n",
    "    for i in range(from_i, int(to_i), 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 20.558048248291016\n",
      "54208 \n",
      " [100000007, 100000037, 100000039, 100000049, 100000073, 100000081, 100000123, 100000127, 100000193, 100000213] \n",
      " [100999889, 100999897, 100999901, 100999903, 100999919, 100999939, 100999949, 100999979, 100999981, 100999993]\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "number_range = range(100000001, 101000000)\n",
    "\n",
    "primes = list(filter(check_prime, number_range))\n",
    "\n",
    "print(\"Took:\", time.time() - t1)\n",
    "print(len(primes), '\\n', primes[:10], '\\n', primes[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multithreaded case, threads compete for jobs while only one thread can be active at a time inside a process although there are multiple launched. However, in this case concurrency is happening but no speed gain. This is a useful case when we are dealing with I/O bound problem when delaying are very likely. While one thread is waiting, another one takes a task to complete it. So more job is done in a period of time. \n",
    "\n",
    "Multiprocessing allows us to launch multiple process each of which has its own Python runtime that can be active independently at the same time. So we can achieve parallel computing here but the problem is how these processes should communicate effectively if working on a shared job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queues - A synchronized queue class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`multiprocessing.Queue` objects give us nonpersistent queues that can send any pickleable Python objects between processes. They carry an overhead, as each object must be\n",
    "pickled to be sent and then unpickled in the consumer (along with some locking operations). In the following example, we’ll see that this cost is not negligible. However, if\n",
    "your workers are processing larger jobs, then the communication overhead is probably acceptable.\n",
    "\n",
    "The two queues are sent as arguments, and multiprocessing handles their synchronization.\n",
    "Having started the new processes, we hand a list of jobs to the `possible_primes_queue` and end with one poison pill per process. The jobs will be consumed in FIFO order, leaving the poison pills for last. In check_prime we use a `blocking .get()`, as the new processes will have to wait for work to appear in the queue. Since we use flags, we could add some work, deal with the results, and then iterate by adding more work, and signal the end of life of the workers by adding the poison pills later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_ALL_DONE = b\"WORK_FINISHED\"\n",
    "FLAG_WORKER_FINISHED_PROCESSING = b\"WORKER_FINSIHED_PROCESSING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define check_prime function as a consumer!\n",
    "def check_prime(possible_primes_queue, definite_primes_queue):\n",
    "    '''\n",
    "    Input: first queue of numbers to be checked for primarity\n",
    "    OutPut: if it is prime, add it to the second queue \n",
    "    '''\n",
    "    while True:\n",
    "        n = possible_primes_queue.get()\n",
    "        if n == FLAG_ALL_DONE:\n",
    "            definite_primes_queue.put(FLAG_WORKER_FINISHED_PROCESSING)\n",
    "            break\n",
    "        else:\n",
    "            if n % 2 == 0:\n",
    "                continue\n",
    "            for i in range(3, int(math.sqrt(n) + 1), 2):\n",
    "                if n % i == 0:\n",
    "                    break\n",
    "            else:\n",
    "                definite_primes_queue.put(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 381.61518692970276\n",
      "54208 [100000007, 100000037, 100000039, 100000049, 100000073, 100000081, 100000123, 100000127, 100000193, 100000213] [100999889, 100999897, 100999901, 100999903, 100999919, 100999939, 100999949, 100999979, 100999981, 100999993]\n"
     ]
    }
   ],
   "source": [
    "primes = []\n",
    "\n",
    "manager = multiprocessing.Manager() # Sync manager\n",
    "possible_primes_queue = manager.Queue()\n",
    "definite_primes_queue = manager.Queue()\n",
    "\n",
    "NBR_PROCESSES = 2\n",
    "processes = []\n",
    "for _ in range(NBR_PROCESSES):\n",
    "    p = multiprocessing.Process(target=check_prime,\n",
    "                                args=(possible_primes_queue, \n",
    "                                      definite_primes_queue))\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "t1 = time.time()\n",
    "number_range = range(100000000, 101000000)\n",
    "\n",
    "for possible_prime in number_range:\n",
    "    possible_primes_queue.put(possible_prime)\n",
    "\n",
    "# add poison pills to stop the remote workers\n",
    "for n in range(NBR_PROCESSES):\n",
    "    possible_primes_queue.put(FLAG_ALL_DONE)\n",
    "\n",
    "processors_indicating_they_have_finished = 0\n",
    "while True:\n",
    "    new_result = definite_primes_queue.get() # block while waiting for results\n",
    "    if new_result == FLAG_WORKER_FINISHED_PROCESSING:\n",
    "        processors_indicating_they_have_finished += 1\n",
    "        if processors_indicating_they_have_finished == NBR_PROCESSES:\n",
    "            break\n",
    "    else:\n",
    "        primes.append(new_result)\n",
    "\n",
    "assert processors_indicating_they_have_finished == NBR_PROCESSES\n",
    "print(\"Took:\", time.time() - t1)\n",
    "print(len(primes), primes[:10], primes[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, multiprocessing can be extremely slow (and therefore useless for small workloads) __if__ processes need to communicate... Multiprocessing has a few substantial limitations. Communication between processes is limited: objects generally need to be serialized or copied to shared memory. This introduces overhead (due to serialization) and complicates building APIs on top of multiprocessing. Starting a subprocess is also more expensive than starting a thread, especially with the “spawn” implementation. Starting a thread takes ~100 µs, while spawning a subprocess takes ~50 ms (50,000 µs) due to Python re-initialization.\n",
    "\n",
    "Finally, many C and C++ libraries support access from multiple threads but do not support access or use across multiple processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No GIL, Thread-Free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the kernel to 3.13t to disable gil. Now threads are free to run as many as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.0 experimental free-threading build (main, Oct  8 2024, 08:51:27) [GCC 13.2.0]\n"
     ]
    }
   ],
   "source": [
    "!python3 -VV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys._is_gil_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queues are thread safe by default. So we can use them if we need to just like we did for processes. This the case of this problem, we dont need anything but a single flag variable as we will see later. But just to have an idea of how this might work, we write the similar code for threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_ALL_DONE = \"WORK_FINISHED\"\n",
    "FLAG_WORKER_FINISHED_PROCESSING = \"WORKER_FINSIHED_PROCESSING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime(possible_primes_queue, definite_primes_queue):\n",
    "    '''\n",
    "    Input: first queue of numbers to be checked for primarity\n",
    "    OutPut: if it is prime, add it to the second queue \n",
    "    '''\n",
    "    print(\"Current SubThread\", threading.get_native_id())\n",
    "    print(\"Active Threads:\", threading.active_count())\n",
    "    while True:\n",
    "        n = possible_primes_queue.get()\n",
    "        if n == FLAG_ALL_DONE:\n",
    "            definite_primes_queue.put(FLAG_WORKER_FINISHED_PROCESSING)\n",
    "            break\n",
    "        else:\n",
    "            if n % 2 == 0:\n",
    "                continue\n",
    "            for i in range(3, int(math.sqrt(n) + 1), 2):\n",
    "                if n % i == 0:\n",
    "                    break\n",
    "            else:\n",
    "                definite_primes_queue.put(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Thread <_MainThread(MainThread, started 139811829039232)>\n",
      "Main Thread ID 1945\n",
      "Active Threads in Main Thread: 15\n",
      "Current Thread 9670\n",
      "Active Threads: 16\n",
      "Current Thread 9671\n",
      "Active Threads: 18\n",
      "Current Thread 9672\n",
      "Active Threads: 19\n",
      "Current Thread 9673\n",
      "Active Threads: 19\n",
      "Took: 27.562790870666504\n",
      "54208 \n",
      " [100000007, 100000037, 100000039, 100000049, 100000073, 100000081, 100000127, 100000123, 100000193, 100000213] \n",
      " [100999889, 100999897, 100999901, 100999919, 100999903, 100999939, 100999949, 100999979, 100999993, 100999981]\n"
     ]
    }
   ],
   "source": [
    "primes = []\n",
    "\n",
    "import queue\n",
    "\n",
    "possible_primes_queue = queue.Queue()\n",
    "definite_primes_queue = queue.Queue()\n",
    "\n",
    "print(\"Main Thread\", threading.main_thread())\n",
    "print(\"Main Thread ID\", threading.get_native_id())\n",
    "print(\"Active Threads in Main Thread:\", threading.active_count())\n",
    "\n",
    "NBR_THREADS = 4\n",
    "threads = []\n",
    "\n",
    "for _ in range(NBR_THREADS):\n",
    "    t = threading.Thread(target=check_prime,\n",
    "                                args=(possible_primes_queue, \n",
    "                                      definite_primes_queue))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "t1 = time.time()\n",
    "number_range = range(100000000, 101000000)\n",
    "\n",
    "for possible_prime in number_range:\n",
    "    possible_primes_queue.put(possible_prime)\n",
    "\n",
    "# add poison pills to stop the remote workers\n",
    "for n in range(NBR_THREADS):\n",
    "    possible_primes_queue.put(FLAG_ALL_DONE)\n",
    "\n",
    "processors_indicating_they_have_finished = 0\n",
    "while True:\n",
    "    new_result = definite_primes_queue.get() # block while waiting for results\n",
    "    if new_result == FLAG_WORKER_FINISHED_PROCESSING:\n",
    "        processors_indicating_they_have_finished += 1\n",
    "        if processors_indicating_they_have_finished == NBR_THREADS:\n",
    "            break\n",
    "    else:\n",
    "        primes.append(new_result)\n",
    "\n",
    "assert processors_indicating_they_have_finished == NBR_THREADS\n",
    "print(\"Took:\", time.time() - t1)\n",
    "print(len(primes), '\\n', primes[:10], '\\n', primes[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we are not getting any speed up because of the overhead from communication. Cooperation comes at a cost—the cost of synchronizing data and checking the shared data can be quite high. We’ll work through several approaches here that can be used in different ways for task coordination ... Can we change the code design to solve this more efficiently? Yes in several ways. We can easily split the searching range into intervals and devote a thread to search in that range for primes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_range(start, end, nbr_threads):\n",
    "    step = (end-start) // nbr_threads\n",
    "    ranges = [(start+step*(i-1), start+step*i) for i in range(1, nbr_threads+1)]\n",
    "    return ranges.append((start+step*nbr_threads, end)) if end-start-step*nbr_threads else ranges\n",
    "\n",
    "def check_prime_in_range(from_i, to_i):\n",
    "    print(\"Current SubThread\", threading.get_native_id())\n",
    "    for n in range(from_i, to_i):\n",
    "        if n % 2 == 0:\n",
    "            continue \n",
    "        for i in range(3, int(math.sqrt(n) + 1), 2):\n",
    "            if n % i == 0:\n",
    "                break\n",
    "        else:\n",
    "            primes.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100000000, 100250000),\n",
       " (100250000, 100500000),\n",
       " (100500000, 100750000),\n",
       " (100750000, 101000000)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START = 100000000\n",
    "END = 101000000\n",
    "NBR_THREADS = 4\n",
    "ranges = create_range(START, END, NBR_THREADS)\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current SubThreadCurrent SubThread 41472\n",
      " 41471\n",
      "Current SubThread 41473\n",
      "Current SubThread 41474\n",
      "Length primes is 54009\n",
      "Length primes is 54061\n",
      "Length primes is 54193\n",
      "Length primes is 54208\n",
      "Took: 11.000897884368896\n",
      "54208 \n",
      " [100250011, 100000007, 100250021, 100500007, 100000037, 100500011, 100250039, 100750019, 100000039, 100500019] \n",
      " [100249859, 100249861, 100249883, 100249907, 100249913, 100249921, 100249931, 100249937, 100249943, 100249987]\n"
     ]
    }
   ],
   "source": [
    "primes = []\n",
    "\n",
    "threads = []\n",
    "# print('Length primes is', len(primes))\n",
    "t1 = time.time()\n",
    "for i in range(len(ranges)):\n",
    "    t = threading.Thread(target=check_prime_in_range,\n",
    "                                args=(ranges[i]))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# join the threads after they all started. \n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# After they joined, the main thread waits here until all child threads are done and returned\n",
    "\n",
    "print(\"Took:\", time.time() - t1)\n",
    "print(len(primes), '\\n', primes[:10], '\\n', primes[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gain some speed here as expected because this way, threads dont need to share data! This is called \"embarrasingly parallel\", which is not the most interesting case in general. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing data between threads in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s define a new problem—suppose we have a small set of numbers and our task is to\n",
    "efficiently use our CPU resources to figure out if each number is a prime, one number\n",
    "at a time. Possibly we’ll have just one large number to test. It no longer makes sense to\n",
    "use one CPU to do the check; we want to coordinate the work across many CPUs.\n",
    "\n",
    "For this section we’ll look at some larger numbers, one with 15 digits and four with 18\n",
    "digits:\n",
    "\n",
    "- Small non-prime: 112272535095295\n",
    "- Large non-prime 1: 100109100129100369\n",
    "- Large non-prime 2: 100109100129101027\n",
    "- Prime 1: 100109100129100151\n",
    "- Prime 2: 100109100129162907\n",
    "\n",
    "For now we will focus on some data sharing methods for threads. Later we’ll work through various ways of using IPC (Interprocess Communication)in Python to solve our cooperative search problem. You’ll see that IPC is fairly easy, but\n",
    "generally comes with a cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a bench mark for speed of multithread solutions, let's first run the single-thread case: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Thread\n",
    "def check_prime_singlet(n):\n",
    "    from_i = 3\n",
    "    to_i = int(math.sqrt(n)) + 1\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "    assert from_i % 2 != 0\n",
    "    for i in range(from_i, to_i, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Small non-prime: 112272535095295, Took: 0.0004241466522216797\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime_singlet(112272535095295))\n",
    "print(\"Small non-prime: 112272535095295, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Large non-prime 1: 1109100129100369, Took: 0.0008904933929443359\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime_singlet(1109100129100369))\n",
    "print(\"Large non-prime 1: 1109100129100369, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Large non-prime 2: 100109100129101027, Took: 9.89187240600586\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime_singlet(100109100129101027))\n",
    "print(\"Large non-prime 2: 100109100129101027, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 1: 100109100129100151, Took: 18.310689210891724\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime_singlet(100109100129100151))\n",
    "print(\"Prime 1: 100109100129100151, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 2: 100109100129162907, Took: 19.632556438446045\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime_singlet(100109100129162907))\n",
    "print(\"Prime 2: 100109100129162907, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Threaded Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the solution, observe that if we have a non-prime, then there’s no way to exit early and we have to manually check all possible factors before we can exit. To solve this, we can flag across all of our processes/threads that a factor has been found, so the search can be called off early. This is called data synchronization.\n",
    "\n",
    "Synchronization becomes more complicated in case of using multi-processes because each process has its own memory. The difficulty is balancing the cost of reading the flag against the speed saving that is possible. \n",
    "\n",
    "By experience the number of threads is taken to be as the number of cpus the machine has. On this machine we have 4 cores - 8 cpus. For this experience, we set the number of threads to be half of #cpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBR_THREADS = os.cpu_count() // 2\n",
    "NBR_THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_range(start, end, NBR_THREADS):\n",
    "    x = (end-start) // NBR_THREADS\n",
    "    ranges = [(start+x*(i-1), start+x*i) for i in range(1, NBR_THREADS)]\n",
    "    ranges.append((start+x*(NBR_THREADS-1), end))\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime_in_range(n, ranges):\n",
    "    global FLAG_SET \n",
    "    from_i, to_i = ranges\n",
    "    for i in range(from_i, to_i, 2):\n",
    "        if FLAG_SET == 1:\n",
    "            return\n",
    "        if n % i == 0:\n",
    "            FLAG_SET = 1\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime(n, NBR_THREADS):\n",
    "    FLAG_SET = 0\n",
    "    # cheaply check high-probability set of possible factors earlier for quick rejection\n",
    "    from_i = 3\n",
    "    to_i = 21\n",
    "    check_prime_in_range(n, (from_i, to_i))\n",
    "    if FLAG_SET == 1:\n",
    "        return False\n",
    "    if n % 2 == 0:\n",
    "        return False \n",
    "    from_i = 3\n",
    "    to_i = int(math.sqrt(n)) + 1\n",
    "    ranges_to_check = create_range(from_i, to_i, NBR_THREADS)\n",
    "    ranges_to_check = list(zip(NBR_THREADS * [n], ranges_to_check))\n",
    "    assert len(ranges_to_check) == NBR_THREADS\n",
    "    threads = []\n",
    "    for i in range(NBR_THREADS):\n",
    "        t = threading.Thread(target=check_prime_in_range,\n",
    "                             args=(ranges_to_check[i]))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    if FLAG_SET == 1:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Large non-prime 1: 1109100129100369, Took: 0.002607583999633789\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(1109100129100369, 2))\n",
    "print(\"Large non-prime 1: 1109100129100369, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Large non-prime 1: 1109100129100369, Took: 0.0022802352905273438\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(1109100129100369, 2))\n",
    "print(\"Large non-prime 1: 1109100129100369, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Large non-prime 2: 100109100129101027, Took: 0.002752542495727539\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129101027, 2))\n",
    "print(\"Large non-prime 2: 100109100129101027, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 1: 100109100129100151, Took: 0.0027174949645996094\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129100151, 2))\n",
    "print(\"Prime 1: 100109100129100151, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 2: 100109100129162907, Took: 0.0029535293579101562\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129162907, 2))\n",
    "print(\"Prime 2: 100109100129162907, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got significant speed gain specially for detecting the large primes. The same performance across all cases unlike the single thread case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronizing File and Variable Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following examples we’ll look at multiple processes sharing and manipulating a\n",
    "state—in this case, four processes incrementing a shared counter a set number of times.\n",
    "Without a synchronization process, the counting is incorrect. If you’re sharing data in\n",
    "a coherent way you’ll always need a method to synchronize the reading and writing of\n",
    "data, or you’ll end up with errors.\n",
    "Typically the synchronization methods are specific to the OS you’re using, and they’re\n",
    "often specific to the language you use. Here we look at file-based synchronization using\n",
    "a Python library and sharing an integer object between Python processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see our first work function. The function iterates over a local counter. In each iteration it opens a file and reads the existing value, increments it by one, and then writes the new value over the old one. On the first iteration the file will be empty or won’t exist, so it will catch an exception and assume the value should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBR_THREADS = os.cpu_count() // 2\n",
    "PATH = './project'\n",
    "MAX_COUNT_PER_THREAD = 10000\n",
    "FILENAME = \"count.txt\"\n",
    "FILEPATH = os.path.join(PATH, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work(filename, max_count):\n",
    "    # Creating a file at specified location\n",
    "    f = open(FILEPATH, \"w\")\n",
    "    f.close()\n",
    "    for _ in range(max_count):\n",
    "        f = open(filename, \"r\")\n",
    "        try:\n",
    "            nbr = int(f.read())\n",
    "        except ValueError as err:\n",
    "            print(\"File is empty, starting to count from 0, error: \" + str(err))\n",
    "            nbr = 0\n",
    "        f = open(filename, \"w\")\n",
    "        f.write(str(nbr + 1) + '\\n')\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is empty, starting to count from 0, error: invalid literal for int() with base 10: ''\n"
     ]
    }
   ],
   "source": [
    "work(FILEPATH, MAX_COUNT_PER_THREAD*NBR_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try this in parallel, as one process/thread writes, the\n",
    "other can read a partially written result that can’t be parsed. This causes an exception, and a zero will be written back. This, in turn, causes our counter to keep getting reset!\n",
    "\n",
    "Using the `lockfile` module, we can introduce a synchronization method so only one\n",
    "process gets to write at a time and the others each await their turn. The overall process\n",
    "therefore runs more slowly, but it doesn’t make mistakes.\n",
    "\n",
    "First, we create a FileLock object;\n",
    "the filename can be anything, but using the same name as the file you want to lock\n",
    "probably makes debugging from the command line easier. When you ask to acquire\n",
    "the lock the FileLock opens a new file with the same name, with .lock appended.\n",
    "acquire without any arguments will block indefinitely, until the lock becomes available.\n",
    "Once you have the lock, you can do your processing without any danger of a conflict.\n",
    "You can then release the lock once you’ve finished writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work(filename, max_count, lock):\n",
    "    for _ in range(max_count):\n",
    "        lock.acquire()\n",
    "        f = open(filename, \"r\")\n",
    "        try:\n",
    "            nbr = int(f.read())\n",
    "        except ValueError as err:\n",
    "            print(\"File is empty, starting to count from 0, error: \" + str(err))\n",
    "            nbr = 0\n",
    "        f = open(filename, \"w\")\n",
    "        f.write(str(nbr + 1) + '\\n')\n",
    "        f.close()\n",
    "        lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_workers():\n",
    "    total_expected_count = NBR_THREADS * MAX_COUNT_PER_THREAD\n",
    "    print(\"Starting {} threads to count to {}\".format(NBR_THREADS, \n",
    "                                                      total_expected_count))\n",
    "    # reset counter\n",
    "    f = open(FILEPATH, \"w\")\n",
    "    f.close()\n",
    "    os.chmod(FILEPATH, 772)\n",
    "    threads = []\n",
    "    lock = threading.Lock()\n",
    "    for _ in range(NBR_THREADS):\n",
    "        p = threading.Thread(target=work, \n",
    "                             args=(FILEPATH, MAX_COUNT_PER_THREAD, lock))\n",
    "        p.start()\n",
    "        threads.append(p)\n",
    "    \n",
    "    for p in threads:\n",
    "        p.join()\n",
    "    print(\"Expecting to see a count of {}\".format(total_expected_count)) \n",
    "    with open(FILEPATH, \"r\") as f:   \n",
    "        print(f\"{FILENAME} contains: {f.read()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 4 threads to count to 40000\n",
      "File is empty, starting to count from 0, error: invalid literal for int() with base 10: ''\n",
      "Expecting to see a count of 40000\n",
      "count.txt contains: 40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much speed gain here... In the same way, we can lock a value that is being manipulated by multiple threads or processes to avoid corrupting data—this is a source of subtle and hard-to-track errors, and this section showed you some robust and lightweight solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following techniques are meaningful for parallel coding through multi processing when it is needed to share data between processes while processes have separate memories. They are not needed for multi-threads when threads are free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPC (Interprocess Communication) for sharing data in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the flag is synchronized, we don’t want to check it too frequently—this adds more overhead.\n",
    "How frequently should we check the shared flag? Each check has a cost, both because\n",
    "we’re adding more instructions to our tight inner loop and because checking requires\n",
    "a lock to be made on the shared variable, which adds more cost. The solution we’ve\n",
    "chosen is to check the flag every 1,000 iterations. Every time we check we look to see if value has been set to FLAG_SET, and if so, we exit the search. If in the search the process finds a factor, then it sets value = FLAG_SET and exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Redis as a Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redis is a key/value in-memory storage engine. It provides its own locking and each\n",
    "operation is atomic, so we don’t have to worry about using locks from inside Python\n",
    "(or from any other interfacing language).\n",
    "By using Redis we make the data storage language-agnostic—any language or tool with\n",
    "an interface to Redis can share data in a compatible way. You could share data between\n",
    "Python, Ruby, C++, and PHP equally easily. You can share data on the local machine or\n",
    "over a network; to share to other machines all you need to do is change the Redis default\n",
    "of sharing only on localhost.\n",
    "Redis lets you store:\n",
    "- Lists of strings\n",
    "- Sets of strings\n",
    "- Sorted sets of strings\n",
    "- Hashes of strings\n",
    "\n",
    "Redis stores everything in RAM and snapshots to disk (optionally using journaling)\n",
    "and supports master/slave replication to a cluster of instances. One possibility with\n",
    "Redis is to use it to share a workload across a cluster, where other machines read and\n",
    "write state and Redis acts as a fast centralized data repository.\n",
    "We can read and write a flag as a text string (all values in Redis are strings) in just the\n",
    "same way as we have been using Python flags previously. We create a StrictRedis\n",
    "interface as a global object, which talks to the external Redis server. We could create a\n",
    "new connection inside check_prime_in_range, but this is slower and can exhaust the\n",
    "limited number of Redis handles that are available.\n",
    "We talk to the Redis server using a dictionary-like access. We can set a value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: Conflict. The container name \"/my-redis\" is already in use by container \"8e462ad22c677f5f0f28d8833955b24d5538fb2ce1498ef11cadb9fa0ebfb5da\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "!docker run -d --name my-redis -p 6379:6379  redis/redis-stack-server:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rds = redis.Redis(\n",
    "    host='127.0.0.1',\n",
    "    port=6379,\n",
    "    charset=\"utf-8\",\n",
    "    decode_responses=True\n",
    "    )\n",
    "connection = rds.ping()\n",
    "\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_NAME = 'redis_primes_flag'\n",
    "FLAG_CLEAR = '0'\n",
    "FLAG_SET = '1'\n",
    "CHECK_EVERY = 1000\n",
    "NBR_PROCESSES = os.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_range(start, end, NBR_PROCESSES):\n",
    "    x = (end-start) // NBR_PROCESSES\n",
    "    ranges = [(start+x*(i-1), start+x*i) for i in range(1, NBR_PROCESSES)]\n",
    "    ranges.append((start+x*(NBR_PROCESSES-1), end))\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime_in_range(n, ranges):\n",
    "    from_i, to_i = ranges\n",
    "    check_every = CHECK_EVERY\n",
    "    for i in range(from_i, to_i, 2):\n",
    "        check_every -= 1\n",
    "        if not check_every:\n",
    "            flag = rds[FLAG_NAME]\n",
    "            if flag == FLAG_SET:\n",
    "                return\n",
    "            check_every = CHECK_EVERY\n",
    "        if n % i == 0:\n",
    "            rds[FLAG_NAME] = FLAG_SET\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime(n, nbr_processes):\n",
    "    # cheaply check high-probability set of possible factors earlier\n",
    "    from_i = 3\n",
    "    to_i = 21\n",
    "    rds[FLAG_NAME] = FLAG_CLEAR\n",
    "    check_prime_in_range(n, (from_i, to_i))\n",
    "    if rds[FLAG_NAME] == FLAG_SET:\n",
    "        return False\n",
    "    if n % 2 == 0:\n",
    "        return False \n",
    "    from_i = 3\n",
    "    to_i = int(math.sqrt(n)) + 1\n",
    "    ranges_to_check = create_range(from_i, to_i, nbr_processes)\n",
    "    ranges_to_check = list(zip(nbr_processes * [n], ranges_to_check))\n",
    "    assert len(ranges_to_check) == nbr_processes\n",
    "    \n",
    "    with Pool(processes=nbr_processes) as pool:\n",
    "        results = pool.starmap(check_prime_in_range, ranges_to_check)\n",
    "    \n",
    "    if False in results:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Small non-prime: 112272535095295, Took: 0.003108501434326172\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(112272535095295, NBR_PROCESSES))\n",
    "print(\"Small non-prime: 112272535095295, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Large non-prime 1: 1109100129100369, Took: 0.0070514678955078125\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(1109100129100369, NBR_PROCESSES))\n",
    "print(\"Large non-prime 1: 1109100129100369, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Large non-prime 2: 100109100129101027, Took: 6.011719226837158\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129101027, NBR_PROCESSES))\n",
    "print(\"Large non-prime 2: 100109100129101027, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 1: 100109100129100151, Took: 33.814987897872925\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129100151, NBR_PROCESSES))\n",
    "print(\"Prime 1: 100109100129100151, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 2: 100109100129162907, Took: 43.31632161140442\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129162907, NBR_PROCESSES))\n",
    "print(\"Prime 2: 100109100129162907, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, multi-processing is much slower than multi threading because of the overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-redis\n",
      "my-redis\n"
     ]
    }
   ],
   "source": [
    "!docker stop my-redis\n",
    "!docker rm my-redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using mmap as a Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get to the fastest way of sharing bytes. Example 9-20 shows a memory-\n",
    "mapped (shared memory) solution using the mmap module. The bytes in a shared\n",
    "memory block are not synchronized, and they come with very little overhead. They act\n",
    "like a file—in this case, they are a block of memory with a file-like interface.\n",
    "\n",
    "Memory mapping is a technique that uses lower-level operating system APIs to load a file directly into computer memory. It can dramatically improve file I/O performance in your program. \n",
    "\n",
    "*Virtual memory* is a way of handling memory management. The operating system uses virtual memory to make it appear that you have more memory than you do, allowing you to worry less about how much memory is available for your programs at any given time. Behind the scenes, your operating system uses parts of your nonvolatile storage, such as your solid-state disk, to simulate additional RAM. mmap uses virtual memory to make it appear that you’ve loaded a very large file into memory, even if the contents of the file are too big to fit in your physical memory.\n",
    "\n",
    "*Shared memory* is another technique provided by your operating system that allows multiple programs to access the same data simultaneously. Shared memory can be a very efficient way of handling data in a program that uses concurrency. Python’s mmap uses shared memory to efficiently share large amounts of data between multiple Python processes, threads, and tasks that are happening concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can picture memory mapping as a process in which read and write operations skip many of the layers of complication and map the requested data directly into physical memory.\n",
    "\n",
    "A memory-mapped file I/O approach sacrifices memory usage for speed, which is classically called the space–time tradeoff. However, memory mapping doesn’t have to use more memory than the conventional approach (that uses `open()` function in with clause and then `read()`). The operating system is very clever. It will lazily load the data as it’s requested, similar to how Python generators work.\n",
    "\n",
    "In addition, thanks to virtual memory, you can load a file that’s larger than your physical memory. However, you won’t see the huge performance improvements from memory mapping when there isn’t enough physical memory for your file, because the operating system will use a slower physical storage medium like a solid-state disk to mimic the physical memory it lacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bytes in a shared\n",
    "memory block are not synchronized, and they come with very little overhead. They act\n",
    "like a file—in this case, they are a block of memory with a file-like interface. We have\n",
    "to seek to a location and read or write sequentially. Typically mmap is used to give a short\n",
    "(memory-mapped) view into a larger file, but in our case, rather than specifying a file\n",
    "number as the first argument, we instead pass -1 to indicate that we want an anonymous\n",
    "block of memory. We could also specify whether we want read-only or write-only access\n",
    "(we want both, which is the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_mem = mmap.mmap(-1, 1) # memory map 1 byte as a flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_CLEAR = 0\n",
    "FLAG_SET = 1\n",
    "CHECK_EVERY = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime_in_range(n, ranges):\n",
    "    from_i, to_i = ranges\n",
    "    check_every = CHECK_EVERY\n",
    "    for i in range(from_i, to_i, 2):\n",
    "        check_every -= 1\n",
    "        if not check_every:\n",
    "            sh_mem.seek(0)\n",
    "            flag = sh_mem.read_byte()\n",
    "            if flag == FLAG_SET:\n",
    "                return False\n",
    "            check_every = CHECK_EVERY\n",
    "        if n % i == 0:\n",
    "            sh_mem.seek(0)\n",
    "            sh_mem.write_byte(FLAG_SET)\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prime(n, nbr_processes):\n",
    "    # cheaply check high-probability set of possible factors earlier\n",
    "    from_i = 3\n",
    "    to_i = 21\n",
    "    sh_mem.seek(0)\n",
    "    sh_mem.write_byte(FLAG_CLEAR)\n",
    "    check_prime_in_range(n, (from_i, to_i))\n",
    "    sh_mem.seek(0)\n",
    "    flag = sh_mem.read_byte()\n",
    "    if flag == FLAG_SET:\n",
    "        return False\n",
    "    if n % 2 == 0:\n",
    "        return False \n",
    "    from_i = 3\n",
    "    to_i = int(math.sqrt(n)) + 1\n",
    "    ranges_to_check = create_range(from_i, to_i, nbr_processes)\n",
    "    ranges_to_check = list(zip(nbr_processes * [n], ranges_to_check))\n",
    "    assert len(ranges_to_check) == nbr_processes\n",
    "    with Pool(processes=nbr_processes) as pool:\n",
    "        pool.starmap(check_prime_in_range, ranges_to_check)\n",
    "\n",
    "    sh_mem.seek(0)\n",
    "    flag = sh_mem.read_byte()\n",
    "    if flag == FLAG_SET:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Small non-prime: 112272535095295, Took: 0.0016758441925048828\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(112272535095295, 4))\n",
    "print(\"Small non-prime: 112272535095295, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Large non-prime 1: 1109100129100369, Took: 0.0003638267517089844\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(1109100129100369, NBR_PROCESSES))\n",
    "print(\"Large non-prime 1: 1109100129100369, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Large non-prime 2: 100109100129101027, Took: 1.6223320960998535\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129101027, NBR_PROCESSES))\n",
    "print(\"Large non-prime 2: 100109100129101027, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 1: 100109100129100151, Took: 10.036401510238647\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129100151, NBR_PROCESSES))\n",
    "print(\"Prime 1: 100109100129100151, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Prime 2: 100109100129162907, Took: 9.678701877593994\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print(check_prime(100109100129162907, NBR_PROCESSES))\n",
    "print(\"Prime 2: 100109100129162907, Took:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mmap supports a number of methods that can be used to move around in the file that it\n",
    "represents (including `find`, `readline`, and `write`). We are using it in the most basic way\n",
    "—we `seek` to the start of the memory block before each read or write and, since we’re\n",
    "sharing just 1 byte, we use read_byte and write_byte to be explicit.\n",
    "There is no Python overhead for locking and no interpretation of the data; we’re dealing\n",
    "with bytes directly with the operating system, so this is our fastest communication\n",
    "method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
